
# Vision-Based Autonomous Navigation | ROS2 & OpenCV üü•üê¢

This project implements a modular, real-time autonomous navigation pipeline for a Turtlesim robot using **ROS2** and **Computer Vision**. The system processes live webcam frames to detect specific visual cues (red objects) and translates them into movement commands while maintaining safety through collision avoidance logic.

## üèóÔ∏è System Architecture

The system is designed with a decentralized approach, utilizing the **Publisher/Subscriber** pattern to ensure modularity and scalability.

1. **Image Detection Node (`image_detection.py`)**:
* Captures live video frames and converts them to the **HSV color space** for robust color segmentation.


* Applies binary masking and contour analysis to isolate the target object.


* Calculates the object's centroid and publishes directional commands (`left`, `right`, `center`, `none`) to a dedicated topic.




2. **Robot Control Node (`robot_control.py`)**:
* Subscribes to directional commands and the robot‚Äôs real-time pose (`/turtle1/pose`).


* Translates high-level directions into precise `Twist` messages (linear and angular velocity).


* 
**Wall Avoidance Logic**: Implements proximity monitoring to prevent collisions with the environment boundaries, ensuring system robustness.





## üß† Key Technical Features

* 
**Real-Time Processing**: Optimized OpenCV pipeline for low-latency object tracking.


* 
**HSV Color Masking**: Superior noise rejection compared to RGB-based detection.


* 
**Modular Node Design**: Separation of concerns allows for easy debugging and potential integration with physical hardware.


* 
**Edge Case Handling**: Integrated safety logic for boundary management.



## üì¶ Installation & Setup

### Prerequisites

* ROS2 (Humble/Foxy)
* Python 3.10+
* OpenCV (`opencv-python`)
* `cv_bridge`

### Build

```bash
# Create and build the workspace
mkdir -p ~/ws_ros2/src
cd ~/ws_ros2/src
git clone https://github.com/RoiAviram/ros2-red-object-tracker.git
cd ..
colcon build --packages-select ros2_opencv
source install/setup.bash

```

## üöÄ Execution

Run the following commands in separate terminals:

1. **Launch Turtlesim Environment**:
`ros2 run turtlesim turtlesim_node`
2. **Start Image Processing Node**:
`ros2 run ros2_opencv image_detection`
3. **Start Movement Control Node**:
`ros2 run ros2_opencv robot_control`

## üé¨ Demo

*(Recommend: Add a GIF here of your optimized LinkedIn video)*

> **Note**: For a full video demonstration including the code and real-time logs, [visit my LinkedIn post](https://www.google.com/search?q=https://www.linkedin.com/posts/roi-aviram_ros2-computervision-robotics-activity-7276941198463299584-p4mU%3Futm_source%3Dshare%26utm_medium%3Dmember_desktop).

---

## üõ†Ô∏è Skills Demonstrated

* 
**Robotics**: ROS2 Humble, Multi-node communication, Topic management.


* 
**Computer Vision**: OpenCV, HSV Segmentation, Contour Analysis.


* 
**Software Engineering**: Python, Linux (Ubuntu), Git, Modular System Design.



---

## üë®‚Äçüíª Author

**Roi Aviram** Electrical and Computer Engineering Student @ Ben-Gurion University.

*Former Algorithm Data Analyst & Automation Engineer (Units 9900, 8200)*.

---
